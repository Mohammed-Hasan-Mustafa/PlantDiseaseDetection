# -*- coding: utf-8 -*-
"""PlantDiseaseDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dt9aTiYMAhD93e2SHIvwvgp22HYlG694
"""

from google.colab import drive
drive.mount('/content/drive')

"""Unzipping all the files from the Zipfile"""

# importing required modules
from zipfile import ZipFile

# specifying the zip file name
file_name = "/content/drive/MyDrive/Plant Disease Detection/archive (1).zip"

# opening the zip file in READ mode
with ZipFile(file_name, 'r') as zip:
    # printing all the contents of the zip file
    zip.printdir()

    # extracting all the files
    print('Extracting all the files now...')
    zip.extractall()
    print('Done!')

"""Installing Split folders"""

pip install split-folders

"""Importing the necessary libraries"""

import pandas as pd
import numpy as np
import os
import keras
import matplotlib.pyplot as plt
from keras.layers import Dense,GlobalAveragePooling2D
from keras.applications import MobileNet
from keras.preprocessing import image
from keras.applications.mobilenet import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.optimizers import Adam
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split

"""Importing the mobilenet model and discards the last 1000 neuron layer.

We add dense layers so that the model can learn more complex functions and classify for better results.
"""

base_model=MobileNet(weights='imagenet',include_top=False)
#imports the mobilenet model and discards the last 1000 neuron layer.

x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x)
#we add dense layers so that the model can learn more complex functions and classify for better results.
x=Dense(1024,activation='relu')(x)
#dense layer 2
x=Dense(512,activation='relu')(x)
#dense layer 3
preds=Dense(38,activation='softmax')(x)
#final layer with softmax activation

model=Model(inputs=base_model.input,outputs=preds)

"""Specify the inputs

Specify the outputs

Now a model has been created based on our architecture
"""

for layer in model.layers[:20]:
    layer.trainable=False
for layer in model.layers[20:]:
    layer.trainable=True

"""Import split folders.

Split with ratio.

To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.
"""

import splitfolders
splitfolders.ratio('/content/plantvillage dataset/segmented', output="output", seed=1337, ratio=(.8, .2), group_prefix=None) # default values

"""Included in our dependencies

This is where you specify the path to the main data folder
"""

train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator=train_datagen.flow_from_directory('./output/train',
                                                 target_size=(224,224),
                                                 color_mode='rgb',
                                                 batch_size=32,
                                                 class_mode='categorical',
                                                 shuffle=True)

val_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)

val_generator=train_datagen.flow_from_directory('./output/val',
                                                 target_size=(224,224),
                                                 color_mode='rgb',
                                                 batch_size=32,
                                                 class_mode='categorical',
                                                 shuffle=True)

model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])
# Adam optimizer
# loss function will be categorical cross entropy
# evaluation metric will be accuracy

step_size_train=train_generator.n//train_generator.batch_size
accident_model=model.fit_generator(generator=train_generator,
                    validation_data =val_generator,
                   steps_per_epoch= step_size_train//50,

                  epochs = 5,
    )

"""Plotting graph for training loss and training accuracy."""

plt.plot(accident_model.history['loss'], label = 'training loss')
plt.plot(accident_model.history['accuracy'], label = 'training accuracy')
plt.grid(True)
plt.legend()

"""Saving the model as "network.h5"
"""

model.save("network.h5")

"""Plotting graph for validation loss and validation accuracy."""

plt.plot(accident_model.history['val_loss'], label = 'validation loss')
plt.plot(accident_model.history['val_accuracy'], label = 'validation accuracy')
plt.grid(True)
plt.legend()

"""Loading the model "network.h5" and the summary of model is displayed."""

from keras.models import load_model
model = load_model('network.h5')
# summarize model.
model.summary()

"""Calculating Model Accuracy"""

print("Calculating Model Accuracy....")
accuracy_score = model.evaluate(val_generator)
print(f"Accuracy: {accuracy_score[1]*100}")

from keras.models import load_model
model.save("network.h5")

"""Importing libraries to"""

# Commented out IPython magic to ensure Python compatibility.
from skimage.color import rgb2gray
import numpy as np
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline
from scipy import ndimage
import pickle

Img_size = 256
clas = ['early_blight','healthy','late_blight']

def cal_per(pth):
    if type(pth)== str:
        img_array = cv2.imread(pth, cv2.IMREAD_COLOR)
        new_img = cv2.resize(img_array, (Img_size,Img_size))
        gray = rgb2gray(new_img)
    else:
        gray = rgb2gray(pth)
    gray_r = gray.reshape(gray.shape[0]*gray.shape[1])
    for i in range(gray_r.shape[0]):
        if gray_r[i] > gray_r.mean():
            gray_r[i] = 255
        elif gray_r[i] > 0.5:
            gray_r[i] = 255
        elif gray_r[i] > 0.25:
            gray_r[i] = 0
        else:
            gray_r[i] = 0
    gray = gray_r.reshape(gray.shape[0],gray.shape[1])
    plt.imshow(gray, cmap='gray')
    x1 = 0
    gr = gray.reshape(-1)
    for i in range(gray.shape[0]*gray.shape[1]):
        if gr[i] != 0:
            x1+= 1
    y1=gray.shape[0]*gray.shape[1]
    z = (y1-x1)/y1
    print("percent of infected part is ", z*100, "%")
    if z <0.3:
        print("Severity stage is 1 and yeild is" , 95 - z*100, "%")
    elif z<0.6 and z >= 0.3:
        print("Severity stage is 2 and yeild is" , 95 - z*100, "%")
    else:
        print("Severity stage is 3 and yeild is" , 95 - z*100, "%")

cal_per('/content/plantvillage dataset/grayscale/Potato___Late_blight/0051e5e8-d1c4-4a84-bf3a-a426cdad6285___RS_LB 4640.JPG')

cal_per('/content/plantvillage dataset/grayscale/Potato___Early_blight/001187a0-57ab-4329-baff-e7246a9edeb0___RS_Early.B 8178.JPG')

cal_per('/content/plantvillage dataset/grayscale/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot/00120a18-ff90-46e4-92fb-2b7a10345bd3___RS_GLSp 9357.JPG')

cal_per('/content/plantvillage dataset/grayscale/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG')

cal_per('/content/plantvillage dataset/grayscale/Tomato___Bacterial_spot/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG')